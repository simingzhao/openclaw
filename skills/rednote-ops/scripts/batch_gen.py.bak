#!/usr/bin/env python3
"""
batch_gen.py â€” æ¢å­çš„æ‰¹é‡å†…å®¹ç”Ÿæˆå™¨

ç‹¬ç«‹è„šæœ¬ï¼Œç”¨ Gemini æ‰¹é‡ç”Ÿæˆå°çº¢ä¹¦å¸–å­ï¼Œä¸èµ° Opusã€‚

ä¸¤ç§æ¨¡å¼ï¼š
  1. from-plan   ä» topic.json çš„ posts è§„åˆ’ä¸­æ‰¹é‡ç”Ÿæˆ
  2. from-sense  ä» sense/latest.json çš„é€‰é¢˜å»ºè®®ç”Ÿæˆ

è¾“å‡º content.json åˆ° content/drafts/{topic_id}/{post_id}_{slug}/

ç”¨æ³•ï¼š
  $VENV batch_gen.py from-plan --topic claude-monetization --posts 01,02,03
  $VENV batch_gen.py from-plan --topic vibe-coding --count 5    # è‡ªåŠ¨é€‰å‰5ä¸ªplanned
  $VENV batch_gen.py from-plan --all --count 10                 # è·¨topicè‡ªåŠ¨é€‰10ä¸ª
  $VENV batch_gen.py from-sense                                 # ä»æœ€æ–°Senseé€‰é¢˜ç”Ÿæˆ
  $VENV batch_gen.py from-sense --count 3                       # åªç”Ÿæˆå‰3ä¸ª
  $VENV batch_gen.py from-sense --input /path/to/latest.json
"""

import argparse
import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path

try:
    from google import genai
    from google.genai import types
except ImportError:
    print("âŒ éœ€è¦ google-genai: pip install google-genai", file=sys.stderr)
    sys.exit(1)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Config
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

MODEL_PRIMARY = os.environ.get("BATCH_MODEL", "gemini-3.1-pro-preview")
MODEL_FALLBACK = "gemini-3-flash-preview"

WORKSPACE = Path(os.environ.get(
    "REDNOTE_WORKSPACE",
    os.path.expanduser("~/.openclaw/workspace-rednote-ops"),
))

DRAFTS_DIR = WORKSPACE / "content" / "drafts"
SENSE_LATEST = WORKSPACE / "sense" / "latest.json"

OBSIDIAN_VAULT = Path(os.path.expanduser(
    "~/Library/Mobile Documents/iCloud~md~obsidian/Documents/OpenClaw_Vault"
))
OBSIDIAN_REDNOTE = OBSIDIAN_VAULT / "Rednote"

TODAY = datetime.now().strftime("%Y-%m-%d")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# é‡‘ç‰Œå†™æ‰‹ System Prompt
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å…±äº«åŸºç¡€ prompt ç‰‡æ®µ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_BASE_IDENTITY = """ä½ æ˜¯ã€Œæ¢å­ã€çš„é‡‘ç‰Œå°çº¢ä¹¦å†™æ‰‹ã€‚

## è´¦å·å®šä½
- å¹³å°ï¼šå°çº¢ä¹¦
- é¢†åŸŸï¼šAIèµšé’±/è¶…çº§ä¸ªä½“ â€” æ•™æ™®é€šäººæ€ä¹ˆé€šè¿‡AIæé’±
- äººè®¾ï¼šæœ‰æ´å¯ŸåŠ›çš„AIå®æˆ˜è€…ï¼Œæ‡‚æŠ€æœ¯è¯´äººè¯ï¼Œè‡ªå·±å°±åœ¨ç”¨AIæäº‹
- è°ƒæ€§ï¼šæ¥åœ°æ°”ã€æœ‰åˆ¤æ–­åŠ›ã€å¶å°”æ¯’èˆŒä½†ä¸åˆ»è–„

## é€šç”¨çº¢çº¿
âŒ ä¸¥ç¦ï¼š
- çº¯bullet pointç½—åˆ—ï¼ˆåƒPPTå¤§çº²ï¼‰
- ä¿¡æ¯æ¬è¿æ— è§‚ç‚¹
- æ¶‰åŠæ”¿æ²»æ•æ„Ÿè¯é¢˜
- æä¸­å›½ç”¨æˆ·ä¸è®¤è¯†çš„å¤–å›½äººåï¼ˆåªå±•ç¤ºæ ¸å¿ƒè§‚ç‚¹å’Œæ•°æ®ï¼‰
- æVPN/ç¿»å¢™/æ¢¯å­ç›¸å…³å†…å®¹

## æœ¬åœŸåŒ–è§„åˆ™ï¼ˆæ­»è§„åˆ™ï¼‰
- IMå·¥å…·ï¼šä¸è¦ç”¨WhatsApp/Telegram/Discord/Slack/iMessageï¼Œç”¨**ä¼ä¸šå¾®ä¿¡/é’‰é’‰/é£ä¹¦/å¾®ä¿¡**
- æ–‡æ¡£å·¥å…·ï¼šGoogle Docsâ†’è…¾è®¯æ–‡æ¡£/é£ä¹¦æ–‡æ¡£ï¼ŒNotionâ†’é£ä¹¦å¤šç»´è¡¨æ ¼/è¯­é›€
- æœç´¢ï¼šGoogleâ†’ç™¾åº¦ï¼ˆæ—¥å¸¸åœºæ™¯ï¼‰ï¼›æŠ€æœ¯åœºæ™¯å¯ä¿ç•™GitHub/VS Codeç­‰
- AIäº§å“å¯ä¿ç•™åŸåï¼šChatGPT/Claude/Gemini/OpenClaw/Cursor
- è´§å¸ï¼š$xxxå»ºè®®æ¢æˆäººæ°‘å¸æˆ–"æœˆå…¥è¿‡ä¸‡"è¿™ç§æ¥åœ°æ°”è¯´æ³•
- ä¸è¦è¯´"åœ¨å›½å†…ä¸èƒ½ç”¨"ï¼Œç›´æ¥è¯´ç”¨ä»€ä¹ˆæ›¿ä»£

## é€šç”¨é£æ ¼
- å¼€å¤´ç¬¬ä¸€å¥å°±è¦æŠ“äººï¼ˆæ•°æ®/åå¸¸è¯†/æ•…äº‹å¼€å¤´ï¼‰
- ç”¨emojiåˆ†éš”æ®µè½ï¼Œä½†ä¸æ»¥ç”¨ï¼ˆæ¯2-3æ®µä¸€ä¸ªï¼‰
- å£è¯­åŒ–ï¼Œåƒæœ‹å‹åœ¨èŠå¤©åˆ†äº«
- è¯´äººè¯ï¼Œä¸ç”¨"èµ‹èƒ½""çŸ©é˜µ""ç”Ÿæ€"è¿™ç±»ç©ºè¯
- æœ‰è‡ªå·±çš„åˆ¤æ–­ï¼š"è¿™ä¸ªé è°±""é‚£ä¸ªæ˜¯å‘"
- **é»˜è®¤ç”¨å®¢è§‚åˆ†æè§†è§’**ï¼Œä¸è¦é€šç¯‡"æˆ‘è¯•äº†""æˆ‘è¸©è¿‡å‘"ï¼Œç”¨æ•°æ®å’Œæ¡ˆä¾‹è¯´è¯
- å¯ä»¥å¶å°”å¸¦ä¸€å¥ä¸ªäººçœ‹æ³•ï¼Œä½†ä¸è¦æ¯ç¯‡éƒ½è£…æˆäº²èº«ç»å†

## é€šç”¨è§„åˆ™
- post_title â‰¤ 20å­—ï¼ˆç¡¬é™åˆ¶ï¼ï¼‰
- post_body 600-950å­—ï¼ˆä¸èƒ½è¶…950ï¼ï¼‰
- å¼€å¤´ä¸è¦"å¤§å®¶å¥½"ä¹‹ç±»çš„åºŸè¯ï¼Œç›´æ¥è¿›ä¸»é¢˜
- ä¸¥æ ¼è¾“å‡º JSONï¼Œä¸è¦è¾“å‡ºä»»ä½•é¢å¤–æ–‡æœ¬
- å¤šç¯‡ç”¨ JSON arrayï¼š[{...}, {...}]
- **JSONæ ¼å¼å…³é”®**ï¼špost_body ä¸­çš„æ¢è¡Œå¿…é¡»å†™æˆ \\nï¼ˆè½¬ä¹‰ï¼‰ï¼Œä¸èƒ½ç”¨çœŸå®æ¢è¡Œï¼å¦åˆ™JSONä¼šè§£æå¤±è´¥ã€‚cover_title åŒç†ã€‚"""

_COVER_RULES = """
## å°é¢æ–‡æ¡ˆè§„åˆ™ï¼ˆcover_titleï¼‰
- ç”¨ \\n æ§åˆ¶æ¢è¡Œï¼Œé€šå¸¸3è¡Œ
- æ¯è¡Œâ‰¤12å­—ï¼Œæ€»è®¡â‰¤36å­—"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# practical æ¨¡å¼ promptï¼ˆå®æ“/æ•™ç¨‹/æ¡ˆä¾‹æ‹†è§£ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROMPT_PRACTICAL = _BASE_IDENTITY + """

## æ¨¡å¼ï¼šå®æ“å¹²è´§ï¼ˆpracticalï¼‰

### å†…å®¹æ ‡å‡†
âœ… å¿…é¡»æœ‰ï¼š
- å¯æ‰§è¡Œçš„å…·ä½“æ­¥éª¤ï¼ˆstep-by-stepï¼‰
- çœŸå®æ¡ˆä¾‹æˆ–æ•°æ®ï¼ˆä¸ç¼–é€ ï¼‰
- è¯»å®Œèƒ½ç›´æ¥åŠ¨æ‰‹çš„è¡ŒåŠ¨æŒ‡å¼•

âŒ é¢å¤–ç¦æ­¢ï¼š
- æ²¡æœ‰æ“ä½œç»†èŠ‚çš„å·¥å…·æ¨è

### ç»“å°¾ç­–ç•¥
- ç»“å°¾å¼•å¯¼è¯„è®ºåŒºè®¨è®ºï¼Œä¸ææ‰£å…³é”®è¯ç§ä¿¡é‚£å¥—
- å¯ä»¥ç”¨çš„ç»“å°¾æ–¹å¼ï¼š
  - æŠ›å‡ºå¼€æ”¾é—®é¢˜ï¼š"ä½ ä»¬æœ‰è¯•è¿‡å—ï¼Ÿæ•ˆæœæ€ä¹ˆæ ·ï¼ŸğŸ‘‡"
  - å¾é›†ç»éªŒï¼š"è¯„è®ºåŒºèŠèŠä½ ç”¨AIæé’±çš„ç»å†"
  - äº’åŠ¨æŠ•ç¥¨ï¼š"ä½ è§‰å¾—xxxé è°±å—ï¼Ÿ"
  - å…³æ³¨å¼•å¯¼ï¼š"è§‰å¾—æœ‰ç”¨ç‚¹ä¸ªå…³æ³¨ï¼Œåç»­æ›´æ–°æ›´å¤šå®æ“"

### è¾“å‡ºå­—æ®µ
```json
{
  "topic_id": "xxx",
  "post_id": "xx",
  "content_mode": "practical",
  "style_id": "hook-cover",
  "cover_title": "å°é¢å¤§å­—\\næ¯è¡Œä¸€ä¸ªé’©å­\\nå«å…·ä½“æ•°å­—",
  "cover_subtitle": "",
  "post_title": "å¸–å­æ ‡é¢˜ï¼ˆâ‰¤20å­—ï¼‰",
  "post_body": "å®Œæ•´æ­£æ–‡ï¼ˆ600-950å­—ï¼‰",
  "tags": ["AI", "æ ‡ç­¾2", "æ ‡ç­¾3", "æ ‡ç­¾4", "æ ‡ç­¾5"],
  "cta_type": "discuss|follow|vote",
  "cta_question": "ç»“å°¾å¼•å¯¼çš„å…·ä½“é—®é¢˜æˆ–è¯æœ¯",
  "status": "draft",
  "created_at": "YYYY-MM-DD"
}
```
""" + _COVER_RULES + """
- å…¬å¼ï¼š[åå¸¸è¯†/èº«ä»½] + [å…·ä½“å·¥å…·/æ–¹æ³•] + [å…·ä½“æ•°å­—ç»“æœ]
- ä¾‹ï¼š"æ–‡ç§‘ç”Ÿé›¶åŸºç¡€\\nç”¨Cursorå†™APP\\n3å‘¨æœˆå…¥$2000"

### æ ‡é¢˜å…¬å¼
- åŒ…å«å…·ä½“æ•°å­—æˆ–ç»“æœ
- åˆ¶é€ å¥½å¥‡å¿ƒç¼ºå£
- å¯ç”¨èº«ä»½æ ‡ç­¾ï¼ˆæ–‡ç§‘ç”Ÿ/å®å¦ˆ/å¤§å­¦ç”Ÿç­‰ï¼‰

### æ­£æ–‡ç»“æ„
- æ¯ä¸ªæ­¥éª¤è¦æœ‰å…·ä½“çš„æ“ä½œç»†èŠ‚ï¼Œä¸æ˜¯ç¬¼ç»Ÿçš„æ–¹å‘
- ç»“å°¾ç”¨è®¨è®º/å…³æ³¨å¼•å¯¼æ”¶å°¾"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# news æ¨¡å¼ promptï¼ˆèµ„è®¯è§£è¯»/è¶‹åŠ¿åˆ†æ/è§‚ç‚¹è¾“å‡ºï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROMPT_NEWS = _BASE_IDENTITY + """

## æ¨¡å¼ï¼šèµ„è®¯è§£è¯»ï¼ˆnewsï¼‰

### å†…å®¹æ ‡å‡†
âœ… å¿…é¡»æœ‰ï¼š
- äº‹ä»¶æœ¬èº«çš„æ¸…æ™°æè¿°ï¼ˆå‘ç”Ÿäº†ä»€ä¹ˆï¼‰
- æ¢å­çš„ç‹¬ç«‹åˆ¤æ–­ï¼ˆè¿™æ„å‘³ç€ä»€ä¹ˆï¼‰
- å¯¹æ™®é€šäººçš„å½±å“åˆ†æï¼ˆè·Ÿä½ æœ‰ä»€ä¹ˆå…³ç³»ï¼‰
- è‡³å°‘1ä¸ªå…·ä½“æ•°æ®ç‚¹

âŒ é¢å¤–ç¦æ­¢ï¼š
- çº¯è½¬è¿°æ— è§‚ç‚¹ï¼ˆ"XXXå‘å¸ƒäº†YYY"ä¸å¤Ÿï¼Œè¦æœ‰"æ‰€ä»¥å‘¢ï¼Ÿ"ï¼‰
- è´©å–ç„¦è™‘ï¼ˆ"ä¸å­¦å°±æ·˜æ±°"ä¹‹ç±»ï¼‰

### ç»“å°¾ç­–ç•¥ï¼ˆä¸ç”¨é’©å­PDFæ¨¡å¼ï¼‰
èµ„è®¯ç±»ç»“å°¾ç”¨ä»¥ä¸‹ä»»ä¸€æ–¹å¼ï¼š
- æŠ›å‡ºå¼€æ”¾é—®é¢˜å¼•å‘è®¨è®ºï¼š"ä½ è§‰å¾—è¿™å¯¹æ™®é€šäººæ˜¯å¥½äº‹è¿˜æ˜¯åäº‹ï¼ŸğŸ‘‡"
- å…³æ³¨å¼•å¯¼ï¼š"å…³æ³¨æˆ‘ï¼Œç¬¬ä¸€æ—¶é—´æ‹†è§£AIåœˆå¤§äº‹"
- äº’åŠ¨å¼•å¯¼ï¼š"ä½ æœ€æƒ³çœ‹æˆ‘æ‹†è§£å“ªä¸ªæ–¹å‘ï¼Ÿè¯„è®ºåŒºå‘Šè¯‰æˆ‘"

### è¾“å‡ºå­—æ®µ
```json
{
  "topic_id": "xxx",
  "post_id": "xx",
  "content_mode": "news",
  "style_id": "hook-cover",
  "cover_title": "å°é¢å¤§å­—\\næ ¸å¿ƒä¿¡æ¯\\nå…³é”®æ•°æ®æˆ–åˆ¤æ–­",
  "cover_subtitle": "",
  "post_title": "å¸–å­æ ‡é¢˜ï¼ˆâ‰¤20å­—ï¼‰",
  "post_body": "å®Œæ•´æ­£æ–‡ï¼ˆ600-950å­—ï¼‰",
  "tags": ["AI", "æ ‡ç­¾2", "æ ‡ç­¾3", "æ ‡ç­¾4", "æ ‡ç­¾5"],
  "cta_type": "discuss|follow|vote",
  "cta_question": "ç»“å°¾å¼•å¯¼çš„å…·ä½“é—®é¢˜",
  "status": "draft",
  "created_at": "YYYY-MM-DD"
}
```

æ³¨æ„ï¼šnewsæ¨¡å¼**æ²¡æœ‰** hook_keyword / pdf_slug / pdf_outline å­—æ®µã€‚
""" + _COVER_RULES + """
- å…¬å¼ï¼š[äº‹ä»¶æ ¸å¿ƒ] + [å…³é”®æ•°æ®/æ—¶é—´] + [æ¢å­åˆ¤æ–­]
- ä¾‹ï¼š"AIå­¦ä¼šæ“ä½œç”µè„‘äº†\\nè¿™æ¬¡æ˜¯çœŸçš„\\næ™®é€šäººè¯¥æ€•è¿˜æ˜¯è¯¥ç¬‘ï¼Ÿ"

### æ ‡é¢˜å…¬å¼
- ç‚¹æ˜äº‹ä»¶ + åŠ å…¥åˆ¤æ–­æˆ–æ‚¬å¿µ
- å¯ä»¥ç”¨ç–‘é—®å¥åˆ¶é€ è®¨è®ºæ¬²
- ä¾‹ï¼š"AIè‡ªå·±ä¼šç”¨ç”µè„‘äº†ï¼Œç¨‹åºå‘˜æ…Œä¸æ…Œï¼Ÿ"

### æ­£æ–‡ç»“æ„
å»ºè®®æŒ‰ä¸‰æ®µå¼ï¼š
1. **å‘ç”Ÿäº†ä»€ä¹ˆ**ï¼ˆ2-3æ®µï¼Œç®€æ´äº¤ä»£äº‹ä»¶+å…³é”®æ•°æ®ï¼‰
2. **æ¢å­æ€ä¹ˆçœ‹**ï¼ˆ2-3æ®µï¼Œç»™å‡ºç‹¬ç«‹åˆ¤æ–­ï¼Œæ•¢è¯´"è¿™ä¸ªè¢«é«˜ä¼°äº†"æˆ–"è¿™æ‰æ˜¯çœŸæ­£çš„æ‹ç‚¹"ï¼‰
3. **è·Ÿä½ æœ‰ä»€ä¹ˆå…³ç³»**ï¼ˆ1-2æ®µï¼Œè½åˆ°æ™®é€šäºº/åˆ›ä½œè€…/è¶…çº§ä¸ªä½“çš„å®é™…å½±å“+è¡ŒåŠ¨å»ºè®®ï¼‰"""

# prompt é€‰æ‹©å™¨
SYSTEM_PROMPTS = {
    "practical": PROMPT_PRACTICAL,
    "news": PROMPT_NEWS,
}

def get_system_prompt(mode: str) -> str:
    return SYSTEM_PROMPTS.get(mode, PROMPT_PRACTICAL)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Gemini è°ƒç”¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def call_gemini(user_prompt: str, batch_size: int = 1, content_mode: str = "practical") -> str | None:
    """è°ƒç”¨ Gemini ç”Ÿæˆå†…å®¹ï¼Œè¿”å›åŸå§‹æ–‡æœ¬ã€‚"""
    client = genai.Client()
    system_prompt = get_system_prompt(content_mode)

    # æŒ‰ç¯‡æ•°åŠ¨æ€è°ƒæ•´ max_output_tokens
    # å•ç¯‡ä¸­æ–‡çº¦ 1000 å­— â‰ˆ ~2000 tokensï¼ŒåŠ ä¸ŠJSONç»“æ„å¼€é”€ç»™ 5000
    tokens_per_post = 5000
    max_tokens = min(tokens_per_post * max(batch_size, 1), 65536)

    for model in [MODEL_PRIMARY, MODEL_FALLBACK]:
        try:
            print(f"  ğŸ¤– æ¨¡å‹: {model} | mode: {content_mode}", file=sys.stderr)
            response = client.models.generate_content(
                model=model,
                contents=user_prompt,
                config=types.GenerateContentConfig(
                    system_instruction=system_prompt,
                    temperature=0.7,
                    max_output_tokens=max_tokens,
                ),
            )
            if response and response.text:
                # æ£€æŸ¥æ˜¯å¦è¢«æˆªæ–­
                finish = getattr(response.candidates[0], 'finish_reason', None) if response.candidates else None
                text_len = len(response.text)
                print(f"  âœ… ç”Ÿæˆå®Œæˆ ({model}) | {text_len}å­— | finish={finish}", file=sys.stderr)
                return response.text
        except Exception as e:
            if any(k in str(e) for k in ["503", "UNAVAILABLE", "429", "RESOURCE_EXHAUSTED"]):
                print(f"  âš ï¸ {model} ä¸å¯ç”¨: {e}", file=sys.stderr)
                continue
            print(f"  âŒ {model} é”™è¯¯: {e}", file=sys.stderr)
            continue

    print("âŒ æ‰€æœ‰æ¨¡å‹éƒ½ä¸å¯ç”¨", file=sys.stderr)
    return None


def _fix_json_newlines(raw: str) -> str:
    """ä¿®å¤ Gemini åœ¨ JSON string value ä¸­æ’å…¥çš„çœŸå®æ¢è¡Œã€‚
    
    é€å­—ç¬¦æ‰«æï¼Œåœ¨ JSON å­—ç¬¦ä¸²å†…éƒ¨ï¼ˆåŒå¼•å·ä¹‹é—´ï¼‰æŠŠ \\n â†’ \\\\nã€‚
    """
    result = []
    in_string = False
    i = 0
    while i < len(raw):
        ch = raw[i]
        if ch == '\\' and in_string and i + 1 < len(raw):
            # ä¿ç•™è½¬ä¹‰åºåˆ—åŸæ ·
            result.append(ch)
            result.append(raw[i + 1])
            i += 2
            continue
        if ch == '"':
            in_string = not in_string
            result.append(ch)
        elif ch == '\n' and in_string:
            result.append('\\n')
        else:
            result.append(ch)
        i += 1
    return ''.join(result)


def parse_json_response(text: str) -> list[dict]:
    """ä» Gemini å“åº”ä¸­è§£æ JSONï¼Œå…¼å®¹å•ç¯‡å’Œå¤šç¯‡ã€‚"""
    raw = text.strip()
    if "```json" in raw:
        raw = raw.split("```json", 1)[1]
        raw = raw.split("```", 1)[0]
    elif "```" in raw:
        raw = raw.split("```", 1)[1]
        raw = raw.split("```", 1)[0]
    raw = raw.strip()

    try:
        data = json.loads(raw)
    except json.JSONDecodeError:
        # Geminiå¸¸åœ¨JSON string valueä¸­æ’å…¥çœŸå®æ¢è¡Œï¼Œéœ€è¦ä¿®å¤
        fixed = _fix_json_newlines(raw)
        try:
            data = json.loads(fixed)
            print(f"  ğŸ”§ JSONè‡ªåŠ¨ä¿®å¤æˆåŠŸï¼ˆè£¸æ¢è¡Œâ†’è½¬ä¹‰ï¼‰", file=sys.stderr)
        except json.JSONDecodeError as e2:
            print(f"âŒ JSONè§£æå¤±è´¥: {e2}", file=sys.stderr)
            print(f"  ç‰‡æ®µ: {text[:500]}", file=sys.stderr)
            return []

    if isinstance(data, list):
        return data
    elif isinstance(data, dict):
        return [data]
    else:
        print(f"âŒ æ„å¤–çš„JSONç±»å‹: {type(data)}", file=sys.stderr)
        return []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# è´¨æ£€
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def validate_post(post: dict) -> list[str]:
    """æ ¡éªŒå•ç¯‡å¸–å­ï¼Œè¿”å›é”™è¯¯åˆ—è¡¨ï¼ˆç©º=é€šè¿‡ï¼‰ã€‚"""
    errors = []
    title = post.get("post_title", "")
    body = post.get("post_body", "")
    cover = post.get("cover_title", "")
    tags = post.get("tags", [])
    mode = post.get("content_mode", "practical")

    if not title:
        errors.append("ç¼ºå°‘ post_title")
    elif len(title) > 20:
        errors.append(f"post_title è¿‡é•¿: {len(title)}å­— (é™20)")

    if not body:
        errors.append("ç¼ºå°‘ post_body")
    elif len(body) < 300:
        errors.append(f"post_body è¿‡çŸ­: {len(body)}å­— (éœ€â‰¥300)")
    elif len(body) > 950:
        errors.append(f"post_body è¿‡é•¿: {len(body)}å­— (é™950)")

    if not cover:
        errors.append("ç¼ºå°‘ cover_title")

    if not tags or len(tags) < 2:
        errors.append("tags å¤ªå°‘ (éœ€â‰¥2)")

    # ä¸¤ç§æ¨¡å¼éƒ½å»ºè®®æœ‰ cta
    if not post.get("cta_type") and not post.get("cta_question") and not post.get("hook_keyword"):
        errors.append("ç¼ºå°‘ç»“å°¾å¼•å¯¼(cta_type/cta_question)")

    return errors


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ä¿å­˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def save_draft(post: dict) -> Path | None:
    """ä¿å­˜å•ç¯‡ content.json åˆ° drafts ç›®å½•ã€‚"""
    topic_id = post.get("topic_id", "unknown")
    post_id = post.get("post_id", "xx")
    title = post.get("post_title", "untitled")

    # ç”Ÿæˆ slug: å–æ ‡é¢˜å‰å‡ ä¸ªå…³é”®å­—
    slug = _make_slug(title)
    dir_name = f"{post_id}_{slug}"
    draft_dir = DRAFTS_DIR / topic_id / dir_name

    # å¦‚æœå·²å­˜åœ¨ï¼Œä¸è¦†ç›–ï¼ˆé™¤é status æ˜¯ plannedï¼‰
    content_path = draft_dir / "content.json"
    if content_path.exists():
        existing = json.loads(content_path.read_text(encoding="utf-8"))
        if existing.get("status") not in ("planned", None):
            print(f"  âš ï¸ è·³è¿‡ {dir_name}: å·²å­˜åœ¨ status={existing.get('status')}", file=sys.stderr)
            return None

    # è¡¥å……å…ƒæ•°æ®
    post.setdefault("status", "draft")
    post.setdefault("created_at", TODAY)
    post.setdefault("published_at", None)
    post.setdefault("published_id", None)
    post.setdefault("style_id", "hook-cover")

    draft_dir.mkdir(parents=True, exist_ok=True)
    with open(content_path, "w", encoding="utf-8") as f:
        json.dump(post, f, ensure_ascii=False, indent=2)

    # åŒæ­¥åˆ° Obsidian
    _sync_to_obsidian(post, dir_name)

    return content_path


def _sync_to_obsidian(post: dict, dir_name: str):
    """æŠŠ draft åŒæ­¥ä¸º Obsidian Markdownï¼Œæ‰‹æœºå¯è¯»ã€‚"""
    if not OBSIDIAN_REDNOTE.exists():
        return  # Obsidian vault ä¸åœ¨æœ¬æœºï¼Œè·³è¿‡

    topic_id = post.get("topic_id", "unknown")
    post_id = post.get("post_id", "xx")
    title = post.get("post_title", "untitled")
    body = post.get("post_body", "")
    cover = post.get("cover_title", "").replace("\\n", "\n")
    tags_list = post.get("tags", [])
    status = post.get("status", "draft")
    mode = post.get("content_mode", "practical")
    hook = post.get("hook_keyword", "")
    cta = post.get("cta_question", "")

    # frontmatter
    tags_yaml = ", ".join(f'"{t}"' for t in tags_list)
    lines = [
        "---",
        f"topic: {topic_id}",
        f"post_id: {post_id}",
        f"status: {status}",
        f"mode: {mode}",
        f"tags: [{tags_yaml}]",
        f"created: {post.get('created_at', TODAY)}",
        "---",
        "",
        f"# {title}",
        "",
        "## å°é¢æ–‡æ¡ˆ",
        f"```",
        cover,
        f"```",
        "",
        "## æ­£æ–‡",
        "",
        body,
        "",
    ]

    if mode == "practical" and hook:
        lines.append(f"## é’©å­")
        lines.append(f"å…³é”®è¯ï¼š**{hook}**")
        pdf_outline = post.get("pdf_outline", [])
        if pdf_outline:
            lines.append(f"PDF: {post.get('pdf_slug', '')}")
            for item in pdf_outline:
                lines.append(f"- {item}")
        lines.append("")
    elif mode == "news" and cta:
        lines.append(f"## CTA")
        lines.append(f"ç±»å‹ï¼š{post.get('cta_type', '?')}")
        lines.append(f"é—®é¢˜ï¼š{cta}")
        lines.append("")

    md_content = "\n".join(lines)

    # å†™å…¥ Obsidian: Rednote/drafts/{topic_id}_{post_id}.md
    ob_dir = OBSIDIAN_REDNOTE / "drafts"
    ob_dir.mkdir(parents=True, exist_ok=True)
    ob_path = ob_dir / f"{topic_id}_{post_id}.md"
    ob_path.write_text(md_content, encoding="utf-8")


def _make_slug(title: str) -> str:
    """ä»æ ‡é¢˜ç”ŸæˆçŸ­ slugã€‚"""
    import re
    # å»æ‰ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™ä¸­æ–‡/è‹±æ–‡/æ•°å­—
    cleaned = re.sub(r'[^\w\u4e00-\u9fff]', '-', title)
    cleaned = re.sub(r'-+', '-', cleaned).strip('-')
    return cleaned[:30] if cleaned else "untitled"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Mode: from-plan
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_topic(topic_id: str) -> dict | None:
    """åŠ è½½ topic.jsonã€‚"""
    path = DRAFTS_DIR / topic_id / "topic.json"
    if not path.exists():
        print(f"âŒ topic.json ä¸å­˜åœ¨: {path}", file=sys.stderr)
        return None
    return json.loads(path.read_text(encoding="utf-8"))


def get_planned_posts(topic: dict, post_ids: list[str] | None = None, count: int | None = None) -> list[dict]:
    """è·å–å¾…ç”Ÿæˆçš„å¸–å­è§„åˆ’ã€‚"""
    posts = topic.get("posts", [])

    if post_ids:
        return [p for p in posts if p["id"] in post_ids]

    # è¿‡æ»¤å·²ç»æœ‰content.jsonçš„ï¼ˆstatus != plannedï¼‰
    planned = []
    for p in posts:
        post_id = p["id"]
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰å†…å®¹
        topic_dir = DRAFTS_DIR / topic["topic_id"]
        found = False
        if topic_dir.exists():
            for sub in topic_dir.iterdir():
                if sub.is_dir() and sub.name.startswith(f"{post_id}_"):
                    cj = sub / "content.json"
                    if cj.exists():
                        existing = json.loads(cj.read_text(encoding="utf-8"))
                        if existing.get("status") not in ("planned", None):
                            found = True
                            break
        if not found:
            planned.append(p)

    # æŒ‰ priority æ’åº
    priority_order = {"high": 0, "medium": 1, "low": 2}
    planned.sort(key=lambda p: priority_order.get(p.get("priority", "low"), 3))

    if count:
        planned = planned[:count]

    return planned


def build_plan_prompt(topic: dict, posts: list[dict], sense_context: str = "") -> str:
    """ä¸º from-plan æ¨¡å¼æ„å»º promptã€‚"""
    lines = []
    lines.append(f"## ä»»åŠ¡")
    lines.append(f"è¯·ä¸ºä»¥ä¸‹é€‰é¢˜è§„åˆ’ç”Ÿæˆå®Œæ•´çš„å°çº¢ä¹¦å¸–å­å†…å®¹ã€‚")
    lines.append(f"æ¯ç¯‡éƒ½è¦ä¸¥æ ¼æŒ‰ç…§ç³»ç»Ÿæç¤ºçš„JSONæ ¼å¼è¾“å‡ºã€‚")
    lines.append(f"å…± {len(posts)} ç¯‡ï¼Œè¯·è¾“å‡º JSON arrayã€‚")
    lines.append(f"")
    lines.append(f"## Topic ä¿¡æ¯")
    lines.append(f"- topic_id: {topic['topic_id']}")
    lines.append(f"- topic_name: {topic['topic_name']}")
    lines.append(f"- angle: {topic.get('topic_angle', '')}")
    lines.append(f"")

    if sense_context:
        lines.append(f"## æœ€æ–°è¶‹åŠ¿ä¿¡å·ï¼ˆå†™ä½œæ—¶å¯å‚è€ƒï¼‰")
        lines.append(sense_context)
        lines.append(f"")

    lines.append(f"## å¾…ç”Ÿæˆçš„å¸–å­")
    for p in posts:
        lines.append(f"")
        lines.append(f"### post_id: {p['id']}")
        lines.append(f"- æ ‡é¢˜æ–¹å‘: {p['title']}")
        lines.append(f"- è§’åº¦: {p.get('angle', '')}")
        lines.append(f"- å†…å®¹ç±»å‹: {p.get('content_type', '')}")
        kps = p.get("key_points", [])
        if kps:
            lines.append(f"- è¦ç‚¹: {'; '.join(kps)}")
        ref = p.get("source_ref", "")
        if ref:
            lines.append(f"- ç´ æå‚è€ƒ: {ref}")

    lines.append(f"")
    lines.append(f"## é‡è¦æé†’")
    lines.append(f"- æ¯ç¯‡ post_body å¿…é¡» 600-950 å­—ï¼Œä¸èƒ½è¶… 950")
    lines.append(f"- post_title â‰¤ 20 å­—")
    lines.append(f"- å¤–å›½äººåä¸è¦å‡ºç°åœ¨æ­£æ–‡é‡Œï¼Œåªå±•ç¤ºè§‚ç‚¹/æ•°æ®/æ–¹æ³•")
    lines.append(f"- æ¯ç¯‡æœ«å°¾ç”¨è®¨è®ºå¼•å¯¼/å…³æ³¨å¼•å¯¼æ”¶å°¾ï¼ˆä¸ææ‰£å…³é”®è¯ç§ä¿¡ï¼‰")
    lines.append(f"- è¾“å‡ºå®Œæ•´ JSON arrayï¼Œç¡®ä¿å¯è§£æ")

    return "\n".join(lines)


def cmd_from_plan(args):
    """ä» topic.json è§„åˆ’ç”Ÿæˆå†…å®¹ã€‚"""
    content_mode = getattr(args, "mode", "practical") or "practical"

    # åŠ è½½ sense ä¸Šä¸‹æ–‡
    sense_ctx = ""
    if SENSE_LATEST.exists():
        try:
            sense = json.loads(SENSE_LATEST.read_text(encoding="utf-8"))
            trends = sense.get("trends", [])[:5]
            if trends:
                sense_ctx = "\n".join(
                    f"- [{t.get('strength','')}] {t.get('signal','')} (æ¥æº: {', '.join(t.get('sources',[]))})"
                    for t in trends
                )
        except Exception:
            pass

    if args.all:
        # è·¨æ‰€æœ‰ topic é€‰
        all_planned = []
        for topic_dir in sorted(DRAFTS_DIR.iterdir()):
            tj = topic_dir / "topic.json"
            if not tj.exists():
                continue
            topic = json.loads(tj.read_text(encoding="utf-8"))
            planned = get_planned_posts(topic, count=None)
            for p in planned:
                p["_topic"] = topic
            all_planned.extend(planned)

        # æŒ‰ priority æ’åºï¼Œå– count
        priority_order = {"high": 0, "medium": 1, "low": 2}
        all_planned.sort(key=lambda p: priority_order.get(p.get("priority", "low"), 3))
        all_planned = all_planned[:args.count or 5]

        if not all_planned:
            print("âŒ æ²¡æœ‰å¾…ç”Ÿæˆçš„å¸–å­", file=sys.stderr)
            return

        # æŒ‰ topic åˆ†ç»„ï¼Œé€ç»„ç”Ÿæˆ
        from collections import defaultdict
        by_topic = defaultdict(list)
        for p in all_planned:
            by_topic[p["_topic"]["topic_id"]].append(p)

        total_ok = 0
        total_fail = 0
        for tid, posts in by_topic.items():
            topic = posts[0]["_topic"]
            ok, fail = _generate_batch(topic, posts, sense_ctx, content_mode)
            total_ok += ok
            total_fail += fail

        print(f"\nâ•â•â• æ€»è®¡: âœ… {total_ok} ç¯‡æˆåŠŸ, âŒ {total_fail} ç¯‡å¤±è´¥ â•â•â•", file=sys.stderr)

    else:
        # å• topic æ¨¡å¼
        topic = load_topic(args.topic)
        if not topic:
            return

        post_ids = [p.strip() for p in args.posts.split(",")] if args.posts else None
        planned = get_planned_posts(topic, post_ids=post_ids, count=args.count)

        if not planned:
            print(f"âŒ æ²¡æœ‰å¾…ç”Ÿæˆçš„å¸–å­ (topic={args.topic})", file=sys.stderr)
            return

        _generate_batch(topic, planned, sense_ctx, content_mode)


def _generate_batch(topic: dict, posts: list[dict], sense_ctx: str, content_mode: str = "practical") -> tuple[int, int]:
    """ä¸ºä¸€ç»„å¸–å­ç”Ÿæˆå†…å®¹ã€‚è¿”å› (æˆåŠŸæ•°, å¤±è´¥æ•°)ã€‚"""
    # æ¯æ¬¡æœ€å¤š3ç¯‡ä¸€èµ·ç”Ÿæˆï¼ˆæ§åˆ¶è´¨é‡å’Œè¾“å‡ºé•¿åº¦ï¼‰
    BATCH_SIZE = 3
    ok_count = 0
    fail_count = 0

    for i in range(0, len(posts), BATCH_SIZE):
        chunk = posts[i:i + BATCH_SIZE]
        ids = [p["id"] for p in chunk]
        print(f"\nğŸ“ ç”Ÿæˆ {topic['topic_id']} / {','.join(ids)} ({len(chunk)}ç¯‡) [mode={content_mode}]", file=sys.stderr)

        prompt = build_plan_prompt(topic, chunk, sense_ctx)
        raw = call_gemini(prompt, batch_size=len(chunk), content_mode=content_mode)

        if not raw:
            fail_count += len(chunk)
            continue

        results = parse_json_response(raw)
        if not results:
            fail_count += len(chunk)
            continue

        for post_data in results:
            # ç¡®ä¿ topic_id æ­£ç¡®
            post_data["topic_id"] = topic["topic_id"]

            # è´¨æ£€
            errors = validate_post(post_data)
            pid = post_data.get("post_id", "??")
            title = post_data.get("post_title", "??")

            if errors:
                print(f"  âš ï¸ [{pid}] {title} â€” è´¨æ£€é—®é¢˜: {'; '.join(errors)}", file=sys.stderr)
                # å°è¯•ä¿®å¤å¸¸è§é—®é¢˜
                post_data = _auto_fix(post_data, errors)
                re_errors = validate_post(post_data)
                if re_errors:
                    print(f"  âŒ [{pid}] ä¿®å¤å¤±è´¥: {'; '.join(re_errors)}", file=sys.stderr)
                    fail_count += 1
                    continue

            # ä¿å­˜
            path = save_draft(post_data)
            if path:
                body_len = len(post_data.get("post_body", ""))
                print(f"  âœ… [{pid}] {title} ({body_len}å­—) â†’ {path.parent.name}/", file=sys.stderr)
                ok_count += 1
            else:
                fail_count += 1

        # æ‰¹æ¬¡é—´ç­‰å¾…ï¼Œé¿å… rate limit
        if i + BATCH_SIZE < len(posts):
            time.sleep(2)

    return ok_count, fail_count


def _auto_fix(post: dict, errors: list[str]) -> dict:
    """è‡ªåŠ¨ä¿®å¤å¸¸è§è´¨æ£€é—®é¢˜ã€‚"""
    # æ ‡é¢˜è¿‡é•¿ â†’ æˆªæ–­
    title = post.get("post_title", "")
    if len(title) > 20:
        # å°è¯•åœ¨åˆé€‚ä½ç½®æˆªæ–­
        for sep in ["ï¼Œ", "ï¼š", "ï¼", "ï¼Ÿ", "ï½œ", " "]:
            idx = title[:20].rfind(sep)
            if 8 <= idx <= 19:
                post["post_title"] = title[:idx]
                break
        else:
            post["post_title"] = title[:20]

    # æ­£æ–‡è¿‡é•¿ â†’ æˆªæ–­åˆ°æœ€åä¸€ä¸ªå®Œæ•´æ®µè½
    body = post.get("post_body", "")
    if len(body) > 950:
        # æ‰¾æœ€åä¸€ä¸ªæ®µè½è¾¹ç•Œ
        cut = body[:950]
        last_newline = cut.rfind("\n")
        if last_newline > 600:
            post["post_body"] = cut[:last_newline].rstrip()
        else:
            post["post_body"] = cut.rstrip()

    return post


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Mode: from-sense
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def cmd_from_sense(args):
    """ä» Sense é€‰é¢˜å»ºè®®ç›´æ¥ç”Ÿæˆå†…å®¹ã€‚"""
    content_mode = getattr(args, "mode", "practical") or "practical"

    sense_path = Path(args.input) if args.input else SENSE_LATEST
    if not sense_path.exists():
        print(f"âŒ Sense latest ä¸å­˜åœ¨: {sense_path}", file=sys.stderr)
        print(f"   è¯·å…ˆè¿è¡Œ sense_scan.py", file=sys.stderr)
        return

    sense = json.loads(sense_path.read_text(encoding="utf-8"))
    suggestions = sense.get("topic_suggestions", [])

    if not suggestions:
        print("âŒ æ²¡æœ‰é€‰é¢˜å»ºè®®", file=sys.stderr)
        return

    count = args.count or len(suggestions)
    suggestions = suggestions[:count]

    # æ„å»ºè¶‹åŠ¿ä¸Šä¸‹æ–‡
    trends = sense.get("trends", [])[:5]
    sense_ctx = "\n".join(
        f"- [{t.get('strength','')}] {t.get('signal','')} (æ¥æº: {', '.join(t.get('sources',[]))})"
        for t in trends
    ) if trends else ""

    # æ„å»ºé«˜èµå¸–å‚è€ƒ
    top_posts = sense.get("top_posts", [])[:5]
    top_ctx = "\n".join(
        f"- ã€Œ{p.get('title','')}ã€ {p.get('likes',0)}èµ/{p.get('collects',0)}è— â€” é’©å­: {p.get('hook_analysis','')}"
        for p in top_posts
    ) if top_posts else ""

    mode_label = "å®æ“å¹²è´§" if content_mode == "practical" else "èµ„è®¯è§£è¯»"
    print(f"â•â•â• ä» Sense é€‰é¢˜ç”Ÿæˆ ({len(suggestions)} ç¯‡) [mode={content_mode} {mode_label}] â•â•â•", file=sys.stderr)

    # æ„å»º prompt
    lines = []
    lines.append("## ä»»åŠ¡")
    lines.append(f"è¯·æ ¹æ®ä»¥ä¸‹ {len(suggestions)} ä¸ªé€‰é¢˜å»ºè®®ï¼Œåˆ†åˆ«ç”Ÿæˆå®Œæ•´çš„å°çº¢ä¹¦å¸–å­å†…å®¹ã€‚")
    lines.append(f"å†…å®¹æ¨¡å¼ï¼š**{mode_label}**ï¼ˆ{content_mode}ï¼‰ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§ç³»ç»Ÿæç¤ºä¸­è¯¥æ¨¡å¼çš„è¦æ±‚è¾“å‡ºã€‚")
    lines.append(f"è¾“å‡º JSON arrayï¼Œæ¯ç¯‡ä¸€ä¸ªå…ƒç´ ã€‚")
    lines.append("")

    if sense_ctx:
        lines.append("## æœ€æ–°è¶‹åŠ¿ä¿¡å·")
        lines.append(sense_ctx)
        lines.append("")

    if top_ctx:
        lines.append("## å½“å‰å°çº¢ä¹¦é«˜èµå¸–å‚è€ƒï¼ˆå­¦ä¹ å®ƒä»¬çš„æ ‡é¢˜å’Œé’©å­ï¼‰")
        lines.append(top_ctx)
        lines.append("")

    lines.append("## é€‰é¢˜åˆ—è¡¨")
    for i, s in enumerate(suggestions, 1):
        lines.append(f"")
        lines.append(f"### é€‰é¢˜ {i}")
        lines.append(f"- æ ‡é¢˜æ–¹å‘: {s.get('title', '')}")
        lines.append(f"- topic_id: {s.get('topic_id', 'new')}")
        lines.append(f"- å†…å®¹ç±»å‹: {s.get('content_type', '')}")
        lines.append(f"- ä¸ºä»€ä¹ˆå†™: {s.get('reasoning', '')}")
        ref = s.get("reference_material", "")
        if ref:
            lines.append(f"- ç´ æå‚è€ƒ: {ref}")
        lines.append(f"- post_id: è¯·ç”¨ n{i:02d} (newsç¼–å·)" if content_mode == "news" else f"- post_id: è¯·ç”¨ s{i:02d} (senseç”Ÿæˆçš„ç¼–å·)")

    lines.append("")
    lines.append("## é‡è¦æé†’")
    lines.append("- æ¯ç¯‡ post_body å¿…é¡» 600-950 å­—")
    lines.append("- post_title â‰¤ 20 å­—")
    lines.append("- å¤–å›½äººåä¸è¦å‡ºç°åœ¨æ­£æ–‡é‡Œ")
    lines.append("- æ¯ç¯‡æœ«å°¾ç”¨è®¨è®ºå¼•å¯¼/å…³æ³¨å¼•å¯¼æ”¶å°¾ï¼ˆä¸ææ‰£å…³é”®è¯ç§ä¿¡ï¼‰")
    lines.append("- å‚è€ƒé«˜èµå¸–çš„æ ‡é¢˜é£æ ¼")
    lines.append("- è¾“å‡ºå®Œæ•´ JSON array")

    prompt = "\n".join(lines)

    raw = call_gemini(prompt, batch_size=len(suggestions), content_mode=content_mode)
    if not raw:
        return

    results = parse_json_response(raw)
    if not results:
        return

    ok = 0
    fail = 0
    for post_data in results:
        # ç¡®ä¿ content_mode å­—æ®µå­˜åœ¨
        post_data.setdefault("content_mode", content_mode)

        errors = validate_post(post_data)
        pid = post_data.get("post_id", "??")
        title = post_data.get("post_title", "??")

        if errors:
            print(f"  âš ï¸ [{pid}] {title} â€” {'; '.join(errors)}", file=sys.stderr)
            post_data = _auto_fix(post_data, errors)
            if validate_post(post_data):
                print(f"  âŒ [{pid}] ä¿®å¤å¤±è´¥", file=sys.stderr)
                fail += 1
                continue

        path = save_draft(post_data)
        if path:
            body_len = len(post_data.get("post_body", ""))
            print(f"  âœ… [{pid}] {title} ({body_len}å­—) â†’ {path.parent.name}/", file=sys.stderr)
            ok += 1
        else:
            fail += 1

    print(f"\nâ•â•â• å®Œæˆ: âœ… {ok} ç¯‡, âŒ {fail} ç¯‡ â•â•â•", file=sys.stderr)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    parser = argparse.ArgumentParser(
        description="æ¢å­æ‰¹é‡å†…å®¹ç”Ÿæˆå™¨ â€” Geminié©±åŠ¨ï¼Œé›¶Opus token",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    sub = parser.add_subparsers(dest="subcommand")

    # from-plan
    p_plan = sub.add_parser("from-plan", help="ä» topic.json å¸–å­è§„åˆ’ç”Ÿæˆ")
    p_plan.add_argument("--topic", "-t", help="topic_id (å¦‚ claude-monetization)")
    p_plan.add_argument("--posts", "-p", help="æŒ‡å®š post_idï¼ˆé€—å·åˆ†éš”ï¼Œå¦‚ 01,02,03ï¼‰")
    p_plan.add_argument("--count", "-n", type=int, help="è‡ªåŠ¨é€‰å‰Nä¸ªplannedå¸–å­")
    p_plan.add_argument("--all", action="store_true", help="è·¨æ‰€æœ‰topicè‡ªåŠ¨é€‰")
    p_plan.add_argument("--mode", "-m", choices=["practical", "news"], default="practical",
                        help="å†…å®¹æ¨¡å¼: practical(å®æ“å¹²è´§) | news(èµ„è®¯è§£è¯»)")

    # from-sense
    p_sense = sub.add_parser("from-sense", help="ä» Sense é€‰é¢˜å»ºè®®ç”Ÿæˆ")
    p_sense.add_argument("--input", "-i", help="Sense latest.json è·¯å¾„")
    p_sense.add_argument("--count", "-n", type=int, help="åªç”Ÿæˆå‰Nä¸ªå»ºè®®")
    p_sense.add_argument("--mode", "-m", choices=["practical", "news"], default="practical",
                        help="å†…å®¹æ¨¡å¼: practical(å®æ“å¹²è´§) | news(èµ„è®¯è§£è¯»)")

    args = parser.parse_args()
    if not args.subcommand:
        parser.print_help()
        sys.exit(1)

    if args.subcommand == "from-plan":
        if not args.all and not args.topic:
            print("âŒ éœ€è¦ --topic æˆ– --all", file=sys.stderr)
            sys.exit(1)
        cmd_from_plan(args)
    elif args.subcommand == "from-sense":
        cmd_from_sense(args)


if __name__ == "__main__":
    main()
