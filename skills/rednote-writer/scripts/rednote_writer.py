#!/usr/bin/env python3
"""å°çº¢ä¹¦ Writer ä¸»æµç¨‹ï¼ˆä»…å†™ä½œä¸åˆ¶å›¾ï¼Œä¸è´Ÿè´£å‘å¸ƒï¼‰ã€‚"""

import argparse
import json
import os
import re
import shutil
import sys
from datetime import datetime

# è·¯å¾„å¸¸é‡
WORKSPACE = os.path.expanduser("~/.openclaw/workspace")
DRAFTS_DIR = os.path.expanduser("~/.openclaw/workspace-rednote-ops/content/drafts")
ICLOUD_DIR = os.path.expanduser(
    "~/Library/Mobile Documents/iCloud~md~obsidian/Documents/OpenClaw_Vault/Rednote"
)

STYLE_CHOICES = ["typography-card", "notes-app", "text-only"]
TYPE_CHOICES = ["brief", "analysis", "opinion", "tools"]

# å¯¼å…¥å…„å¼Ÿæ¨¡å—
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, SCRIPT_DIR)

from content_gen import generate_content, load_digest, load_latest_digest
from card_gen import generate_cards


def slugify(text: str) -> str:
    raw = (text or "").strip().lower()
    raw = re.sub(r"[\s_/|]+", "-", raw)
    raw = re.sub(r"[^a-z0-9\u4e00-\u9fff\-]", "", raw)
    raw = re.sub(r"-+", "-", raw).strip("-")
    return raw or "untitled"


def resolve_date_for_dir(date_str: str | None = None) -> str:
    if not date_str:
        return datetime.now().strftime("%Y-%m-%d")

    s = date_str.strip()
    if re.match(r"^\d{4}-\d{2}-\d{2}$", s):
        return s

    m = re.match(r"^(\d{2})[.\-/](\d{2})$", s)
    if m:
        return f"{datetime.now().year}-{m.group(1)}-{m.group(2)}"

    return datetime.now().strftime("%Y-%m-%d")


def get_title_for_dir(data: dict) -> str:
    return (
        data.get("post_title")
        or data.get("cover_title")
        or data.get("title")
        or "rednote-draft"
    )


def make_output_dir(title: str, date_str: str | None = None) -> str:
    date_part = resolve_date_for_dir(date_str)
    dir_name = f"{date_part}_{slugify(title)}"
    out_dir = os.path.join(DRAFTS_DIR, dir_name)
    os.makedirs(out_dir, exist_ok=True)
    return out_dir


def save_content_files(out_dir: str, data: dict) -> tuple[str, str]:
    """ä¿å­˜å†…å®¹å…ƒæ•°æ®ï¼ˆcontent.json + content.txtï¼‰ã€‚"""
    json_path = os.path.join(out_dir, "content.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    txt_path = os.path.join(out_dir, "content.txt")
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write(f"æ ‡é¢˜: {get_title_for_dir(data)}\n")
        if data.get("cover_title") or data.get("cover_subtitle"):
            f.write(f"å°é¢: {data.get('cover_title', '')} | {data.get('cover_subtitle', '')}\n")
        if data.get("post_title"):
            f.write(f"å¸–å­æ ‡é¢˜: {data.get('post_title')}\n")
        if data.get("tags"):
            f.write(f"Tags: {', '.join(data.get('tags', []))}\n")

        f.write(f"\n{'=' * 50}\næ­£æ–‡:\n{'=' * 50}\n\n")
        if data.get("post_body"):
            f.write(data.get("post_body", ""))
        elif data.get("body"):
            f.write(data.get("body", ""))

        items = data.get("items") or []
        sections = data.get("sections") or []
        tools = data.get("tools") or []

        if items:
            f.write(f"\n\n{'=' * 50}\nå¡ç‰‡é¡¹:\n{'=' * 50}\n\n")
            for i, item in enumerate(items, 1):
                f.write(f"[{i}] {item.get('title', '')}\n")
                f.write(f"{item.get('body', '')}\n\n")

        if sections:
            f.write(f"\n\n{'=' * 50}\nç« èŠ‚:\n{'=' * 50}\n\n")
            for i, sec in enumerate(sections, 1):
                f.write(f"[{i}] {sec.get('heading', '')}\n")
                for point in sec.get("points", []):
                    f.write(f"- {point}\n")
                if sec.get("quote"):
                    f.write(f"  é‡‘å¥: {sec.get('quote')}\n")
                f.write("\n")

        if tools:
            f.write(f"\n\n{'=' * 50}\nå·¥å…·:\n{'=' * 50}\n\n")
            for i, tool in enumerate(tools, 1):
                f.write(f"[{i}] {tool.get('name', '')}\n")
                if tool.get("description"):
                    f.write(f"  è¯´æ˜: {tool.get('description')}\n")
                if tool.get("verdict"):
                    f.write(f"  ç»“è®º: {tool.get('verdict')}\n")
                f.write("\n")

    print(f"ğŸ’¾ å†…å®¹JSON: {json_path}")
    print(f"ğŸ’¾ å†…å®¹æ–‡æœ¬: {txt_path}")
    return json_path, txt_path


def save_meta(
    out_dir: str,
    style_id: str,
    content_type: str,
    card_count: int,
) -> str:
    meta = {
        "style_id": style_id,
        "content_type": content_type,
        "created_at": datetime.now().isoformat(timespec="seconds"),
        "card_count": card_count,
    }
    meta_path = os.path.join(out_dir, "meta.json")
    with open(meta_path, "w", encoding="utf-8") as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ å…ƒä¿¡æ¯: {meta_path}")
    return meta_path


def sync_to_icloud(out_dir: str) -> None:
    """åŒæ­¥åˆ° iCloud Obsidian Vaultã€‚"""
    os.makedirs(ICLOUD_DIR, exist_ok=True)
    dir_name = os.path.basename(out_dir)
    dest = os.path.join(ICLOUD_DIR, dir_name)

    if os.path.exists(dest):
        shutil.rmtree(dest)
    shutil.copytree(out_dir, dest)
    print(f"â˜ï¸ iCloudåŒæ­¥: {dest}")


def pipeline_daily_brief(args):
    """æ—¥æŠ¥å®Œæ•´ Pipeline: ç´ æ -> content_gen -> card_gen -> saveã€‚"""
    print("=" * 60)
    print("ğŸ“¡ Step 1: åŠ è½½å·¡é€»ç´ æ")
    print("=" * 60)

    if args.input:
        digest_text = load_digest(args.input)
        date_str = args.date or datetime.now().strftime("%m.%d")
    else:
        digest_text, date_str = load_latest_digest(args.workspace, args.source)
        if args.date:
            date_str = args.date

    print(f"âœ… ç´ æé•¿åº¦: {len(digest_text)}å­—\n")

    print("=" * 60)
    print("ğŸ¤– Step 2: Gemini ç²¾ä¿®å†…å®¹")
    print("=" * 60)

    data = generate_content(digest_text, date_str, content_type=args.type)
    print()

    print("=" * 60)
    print("ğŸ¨ Step 3: ç”Ÿæˆå¡ç‰‡")
    print("=" * 60)

    out_dir = make_output_dir(get_title_for_dir(data), date_str)
    cards_dir = os.path.join(out_dir, "cards")
    card_paths = generate_cards(style_id=args.style, content_data=data, output_dir=cards_dir)
    data["card_paths"] = card_paths
    print(f"âœ… å…± {len(card_paths)} å¼ å¡ç‰‡\n")

    print("=" * 60)
    print("ğŸ’¾ Step 4: ä¿å­˜å†…å®¹")
    print("=" * 60)

    save_content_files(out_dir, data)
    save_meta(out_dir, args.style, args.type, len(card_paths))
    print()

    print("=" * 60)
    print("â˜ï¸ Step 5: iCloud åŒæ­¥")
    print("=" * 60)

    sync_to_icloud(out_dir)
    print(f"\nğŸ“‚ è¾“å‡ºç›®å½•: {out_dir}")
    return out_dir, data


def pipeline_from_json(args):
    """ä»å·²æœ‰ content.json ç”Ÿæˆå¡ç‰‡å¹¶ä¿å­˜åˆ°è‰ç¨¿ç›®å½•ã€‚"""
    with open(args.input, "r", encoding="utf-8") as f:
        data = json.load(f)

    out_dir = make_output_dir(get_title_for_dir(data), args.date)
    cards_dir = os.path.join(out_dir, "cards")
    card_paths = generate_cards(style_id=args.style, content_data=data, output_dir=cards_dir)

    data["card_paths"] = card_paths
    save_content_files(out_dir, data)
    save_meta(out_dir, args.style, args.type, len(card_paths))
    sync_to_icloud(out_dir)

    print(f"\nğŸ“‚ è¾“å‡ºç›®å½•: {out_dir}")
    return out_dir, data


def main():
    parser = argparse.ArgumentParser(description="å°çº¢ä¹¦ Writer Pipelineï¼ˆå†™ä½œ+åˆ¶å›¾ï¼‰")
    sub = parser.add_subparsers(dest="command")

    # daily-brief
    p_daily = sub.add_parser("daily-brief", help="æ—¥æŠ¥å®Œæ•´ Pipeline")
    p_daily.add_argument("--workspace", "-w", default=WORKSPACE)
    p_daily.add_argument("--source", "-s", choices=["x", "youtube", "both"], default="both")
    p_daily.add_argument("--input", "-i", help="æ‰‹åŠ¨æŒ‡å®š digest æ–‡ä»¶ï¼ˆè¦†ç›– auto æ¨¡å¼ï¼‰")
    p_daily.add_argument("--date", "-d", help="æ—¥æœŸï¼ˆMM.DD æˆ– YYYY-MM-DDï¼‰")
    p_daily.add_argument("--style", choices=STYLE_CHOICES, default="typography-card")
    p_daily.add_argument("--type", choices=TYPE_CHOICES, default="brief")

    # from-json
    p_json = sub.add_parser("from-json", help="ä»å·²æœ‰ content.json ç”Ÿæˆå¡ç‰‡")
    p_json.add_argument("--input", "-i", required=True, help="content.json è·¯å¾„")
    p_json.add_argument("--date", "-d", help="æ—¥æœŸï¼ˆMM.DD æˆ– YYYY-MM-DDï¼‰")
    p_json.add_argument("--style", choices=STYLE_CHOICES, default="typography-card")
    p_json.add_argument("--type", choices=TYPE_CHOICES, default="brief")

    args = parser.parse_args()
    if not args.command:
        parser.print_help()
        sys.exit(1)

    if args.command == "daily-brief":
        pipeline_daily_brief(args)
    elif args.command == "from-json":
        pipeline_from_json(args)


if __name__ == "__main__":
    main()
