#!/usr/bin/env python3
"""
å¾®ä¿¡å…¬ä¼—å· API å°è£…è„šæœ¬

ç¯å¢ƒå˜é‡:
    WECHAT_APPID: å…¬ä¼—å· AppID
    WECHAT_APPSECRET: å…¬ä¼—å· AppSecret

ä½¿ç”¨ç¤ºä¾‹:
    python wechat_api.py token
    python wechat_api.py upload-cover cover.jpg
    python wechat_api.py md2html article.md -o article.html
    python wechat_api.py draft-add --title "æ ‡é¢˜" --from-md article.md --thumb-media-id xxx
    python wechat_api.py draft-list --human
"""

import argparse
import json
import os
import sys
import time
from pathlib import Path
from typing import Any, Optional

import requests

# Token ç¼“å­˜æ–‡ä»¶è·¯å¾„
TOKEN_CACHE_FILE = Path.home() / ".wechat_token.json"

# API ç«¯ç‚¹
API_BASE = "https://api.weixin.qq.com/cgi-bin"
ENDPOINTS = {
    "token": f"{API_BASE}/token",
    "upload_material": f"{API_BASE}/material/add_material",
    "upload_image": f"{API_BASE}/media/uploadimg",
    "draft_add": f"{API_BASE}/draft/add",
    "draft_batchget": f"{API_BASE}/draft/batchget",
    "draft_get": f"{API_BASE}/draft/get",
    "draft_update": f"{API_BASE}/draft/update",
    "draft_delete": f"{API_BASE}/draft/delete",
    "publish_submit": f"{API_BASE}/freepublish/submit",
    "publish_get": f"{API_BASE}/freepublish/get",
    "publish_batchget": f"{API_BASE}/freepublish/batchget",
}


def get_credentials() -> tuple[str, str]:
    """ä»ç¯å¢ƒå˜é‡è·å– AppID å’Œ AppSecret"""
    appid = os.environ.get("WECHAT_APPID")
    appsecret = os.environ.get("WECHAT_APPSECRET")
    
    if not appid or not appsecret:
        print("é”™è¯¯: è¯·è®¾ç½®ç¯å¢ƒå˜é‡ WECHAT_APPID å’Œ WECHAT_APPSECRET", file=sys.stderr)
        sys.exit(1)
    
    return appid, appsecret


def load_token_cache() -> Optional[dict]:
    """åŠ è½½ç¼“å­˜çš„ token"""
    if not TOKEN_CACHE_FILE.exists():
        return None
    
    try:
        with open(TOKEN_CACHE_FILE, "r") as f:
            return json.load(f)
    except (json.JSONDecodeError, IOError):
        return None


def save_token_cache(token: str, expires_at: float) -> None:
    """ä¿å­˜ token åˆ°ç¼“å­˜"""
    cache = {
        "access_token": token,
        "expires_at": expires_at
    }
    with open(TOKEN_CACHE_FILE, "w") as f:
        json.dump(cache, f, indent=2)


def get_access_token(force_refresh: bool = False) -> str:
    """
    è·å– access_tokenï¼ˆè‡ªåŠ¨ç¼“å­˜ï¼Œè¿‡æœŸå‰10åˆ†é’Ÿåˆ·æ–°ï¼‰
    
    Args:
        force_refresh: å¼ºåˆ¶åˆ·æ–° token
    
    Returns:
        access_token å­—ç¬¦ä¸²
    """
    # æ£€æŸ¥ç¼“å­˜
    if not force_refresh:
        cache = load_token_cache()
        if cache:
            # è¿‡æœŸå‰ 10 åˆ†é’Ÿåˆ·æ–°
            if cache.get("expires_at", 0) > time.time() + 600:
                return cache["access_token"]
    
    # è¯·æ±‚æ–° token
    appid, appsecret = get_credentials()
    
    resp = requests.get(ENDPOINTS["token"], params={
        "grant_type": "client_credential",
        "appid": appid,
        "secret": appsecret
    })
    
    data = resp.json()
    
    if "errcode" in data and data["errcode"] != 0:
        print(f"é”™è¯¯: {data.get('errmsg', 'æœªçŸ¥é”™è¯¯')} (errcode: {data['errcode']})", file=sys.stderr)
        sys.exit(1)
    
    token = data["access_token"]
    expires_in = data.get("expires_in", 7200)
    expires_at = time.time() + expires_in
    
    # ä¿å­˜ç¼“å­˜
    save_token_cache(token, expires_at)
    
    return token


def check_response(data: dict) -> dict:
    """æ£€æŸ¥ API å“åº”ï¼Œå¦‚æœ‰é”™è¯¯åˆ™é€€å‡º"""
    if "errcode" in data and data["errcode"] != 0:
        print(f"é”™è¯¯: {data.get('errmsg', 'æœªçŸ¥é”™è¯¯')} (errcode: {data['errcode']})", file=sys.stderr)
        sys.exit(1)
    return data


def output_result(data: Any, human: bool = False) -> None:
    """è¾“å‡ºç»“æœ"""
    if human:
        if isinstance(data, dict):
            for key, value in data.items():
                if isinstance(value, (dict, list)):
                    print(f"{key}:")
                    print(json.dumps(value, ensure_ascii=False, indent=2))
                else:
                    print(f"{key}: {value}")
        elif isinstance(data, list):
            for i, item in enumerate(data):
                print(f"[{i}] {json.dumps(item, ensure_ascii=False)}")
        else:
            print(data)
    else:
        print(json.dumps(data, ensure_ascii=False, indent=2))


# ============ Token å‘½ä»¤ ============

def cmd_token(args: argparse.Namespace) -> None:
    """è·å–å¹¶æ˜¾ç¤ºå½“å‰ access_token"""
    token = get_access_token()
    
    cache = load_token_cache()
    expires_at = cache.get("expires_at", 0) if cache else 0
    remaining = max(0, int(expires_at - time.time()))
    
    result = {
        "access_token": token,
        "expires_in": remaining,
        "expires_at": expires_at
    }
    
    if args.human:
        print(f"Access Token: {token[:20]}...{token[-10:]}")
        print(f"å‰©ä½™æœ‰æ•ˆæœŸ: {remaining // 60} åˆ†é’Ÿ {remaining % 60} ç§’")
    else:
        output_result(result)


# ============ ç´ æä¸Šä¼ å‘½ä»¤ ============

def cmd_upload_cover(args: argparse.Namespace) -> None:
    """ä¸Šä¼ æ°¸ä¹…ç´ æï¼ˆå°é¢å›¾ï¼‰"""
    image_path = Path(args.image_path)
    
    if not image_path.exists():
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {image_path}", file=sys.stderr)
        sys.exit(1)
    
    token = get_access_token()
    
    with open(image_path, "rb") as f:
        files = {"media": (image_path.name, f, "image/jpeg")}
        resp = requests.post(
            ENDPOINTS["upload_material"],
            params={"access_token": token, "type": "image"},
            files=files
        )
    
    data = check_response(resp.json())
    
    if args.human:
        print(f"media_id: {data.get('media_id')}")
        print(f"url: {data.get('url')}")
    else:
        output_result(data)


def cmd_upload_image(args: argparse.Namespace) -> None:
    """ä¸Šä¼ å›¾æ–‡æ¶ˆæ¯å›¾ç‰‡"""
    image_path = Path(args.image_path)
    
    if not image_path.exists():
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {image_path}", file=sys.stderr)
        sys.exit(1)
    
    token = get_access_token()
    
    with open(image_path, "rb") as f:
        files = {"media": (image_path.name, f, "image/jpeg")}
        resp = requests.post(
            ENDPOINTS["upload_image"],
            params={"access_token": token},
            files=files
        )
    
    data = check_response(resp.json())
    
    if args.human:
        print(f"url: {data.get('url')}")
    else:
        output_result(data)


# ============ è‰ç¨¿ç®¡ç†å‘½ä»¤ ============

def cmd_draft_add(args: argparse.Namespace) -> None:
    """åˆ›å»ºè‰ç¨¿"""
    token = get_access_token()
    
    if args.json_file:
        # ä» JSON æ–‡ä»¶è¯»å–
        json_path = Path(args.json_file)
        if not json_path.exists():
            print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {json_path}", file=sys.stderr)
            sys.exit(1)
        
        with open(json_path, "r", encoding="utf-8") as f:
            payload = json.load(f)

        # å…¼å®¹ä¸¤ç§ JSON ç»“æ„ï¼š
        # 1) ç›´æ¥æ˜¯ {"articles": [...]}ï¼ˆå¾®ä¿¡å®˜æ–¹ draft/add éœ€è¦çš„ç»“æ„ï¼‰
        # 2) å•ç¯‡æ–‡ç«  {"title":..., "content":..., "thumb_media_id":...}ï¼ˆå†å²ç”¨æ³•ï¼‰
        if isinstance(payload, dict) and "articles" not in payload:
            required = {"title", "content", "thumb_media_id"}
            if required.issubset(payload.keys()):
                payload = {"articles": [payload]}

        # è‹¥ä¼ å…¥çš„æ˜¯åˆ—è¡¨ï¼Œåˆ™é»˜è®¤è§†ä¸º articles åˆ—è¡¨
        if isinstance(payload, list):
            payload = {"articles": payload}
    else:
        # ä»å‘½ä»¤è¡Œå‚æ•°æ„å»º
        # æ”¯æŒä» Markdown æ–‡ä»¶è‡ªåŠ¨è½¬æ¢
        content = args.content
        title = args.title
        if getattr(args, 'from_md', None):
            md_path = Path(args.from_md)
            if not md_path.exists():
                print(f"é”™è¯¯: Markdown æ–‡ä»¶ä¸å­˜åœ¨: {md_path}", file=sys.stderr)
                sys.exit(1)
            with open(md_path, 'r', encoding='utf-8') as f:
                md_text = f.read()
            extracted_title, content = markdown_to_wechat_html(md_text)
            if not title:
                title = extracted_title

        if not title or not content or not args.thumb_media_id:
            print("é”™è¯¯: éœ€è¦æä¾› --title, --content (æˆ– --from-md) å’Œ --thumb-media-idï¼Œæˆ–è€…æä¾› JSON æ–‡ä»¶", file=sys.stderr)
            sys.exit(1)

        article = {
            "title": title,
            "content": content,
            "thumb_media_id": args.thumb_media_id,
        }
        
        if args.author:
            article["author"] = args.author
        if args.digest:
            article["digest"] = args.digest
        if args.content_source_url:
            article["content_source_url"] = args.content_source_url
        if args.need_open_comment is not None:
            article["need_open_comment"] = 1 if args.need_open_comment else 0
        if args.only_fans_can_comment is not None:
            article["only_fans_can_comment"] = 1 if args.only_fans_can_comment else 0
        
        payload = {"articles": [article]}
    
    resp = requests.post(
        ENDPOINTS["draft_add"],
        params={"access_token": token},
        data=json.dumps(payload, ensure_ascii=False).encode('utf-8'),
        headers={"Content-Type": "application/json; charset=utf-8"}
    )
    
    data = check_response(resp.json())
    
    if args.human:
        print(f"è‰ç¨¿åˆ›å»ºæˆåŠŸï¼")
        print(f"media_id: {data.get('media_id')}")
    else:
        output_result(data)


def cmd_draft_list(args: argparse.Namespace) -> None:
    """åˆ—å‡ºæ‰€æœ‰è‰ç¨¿"""
    token = get_access_token()
    
    payload = {
        "offset": args.offset,
        "count": args.count,
        "no_content": 1 if args.no_content else 0
    }
    
    resp = requests.post(
        ENDPOINTS["draft_batchget"],
        params={"access_token": token},
        json=payload
    )
    
    data = check_response(resp.json())
    
    if args.human:
        print(f"å…± {data.get('total_count', 0)} ç¯‡è‰ç¨¿")
        print("-" * 50)
        for i, item in enumerate(data.get("item", [])):
            content = item.get("content", {})
            news = content.get("news_item", [{}])[0] if content.get("news_item") else {}
            print(f"[{i + 1}] {news.get('title', 'æ— æ ‡é¢˜')}")
            print(f"    media_id: {item.get('media_id')}")
            print(f"    æ›´æ–°æ—¶é—´: {item.get('update_time')}")
            print()
    else:
        output_result(data)


def cmd_draft_get(args: argparse.Namespace) -> None:
    """è·å–è‰ç¨¿è¯¦æƒ…"""
    token = get_access_token()
    
    resp = requests.post(
        ENDPOINTS["draft_get"],
        params={"access_token": token},
        json={"media_id": args.media_id}
    )
    
    data = check_response(resp.json())
    
    if args.human:
        news_items = data.get("news_item", [])
        for i, article in enumerate(news_items):
            print(f"=== æ–‡ç«  {i + 1} ===")
            print(f"æ ‡é¢˜: {article.get('title')}")
            print(f"ä½œè€…: {article.get('author', 'æ— ')}")
            print(f"æ‘˜è¦: {article.get('digest', 'æ— ')}")
            print(f"å°é¢ media_id: {article.get('thumb_media_id')}")
            print()
    else:
        output_result(data)


def cmd_draft_update(args: argparse.Namespace) -> None:
    """æ›´æ–°è‰ç¨¿"""
    token = get_access_token()
    
    articles = {}
    if args.title:
        articles["title"] = args.title
    if args.content:
        articles["content"] = args.content
    if args.thumb_media_id:
        articles["thumb_media_id"] = args.thumb_media_id
    if args.author:
        articles["author"] = args.author
    if args.digest:
        articles["digest"] = args.digest
    
    if not articles:
        print("é”™è¯¯: è‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæ›´æ–°å­—æ®µ", file=sys.stderr)
        sys.exit(1)
    
    payload = {
        "media_id": args.media_id,
        "index": args.index,
        "articles": articles
    }
    
    resp = requests.post(
        ENDPOINTS["draft_update"],
        params={"access_token": token},
        data=json.dumps(payload, ensure_ascii=False).encode('utf-8'),
        headers={"Content-Type": "application/json; charset=utf-8"}
    )
    
    data = check_response(resp.json())
    
    if args.human:
        print("è‰ç¨¿æ›´æ–°æˆåŠŸï¼")
    else:
        output_result(data)


def cmd_draft_delete(args: argparse.Namespace) -> None:
    """åˆ é™¤è‰ç¨¿"""
    token = get_access_token()
    
    resp = requests.post(
        ENDPOINTS["draft_delete"],
        params={"access_token": token},
        json={"media_id": args.media_id}
    )
    
    data = check_response(resp.json())
    
    if args.human:
        print("è‰ç¨¿åˆ é™¤æˆåŠŸï¼")
    else:
        output_result(data)


# ============ å‘å¸ƒç®¡ç†å‘½ä»¤ ============

def cmd_publish(args: argparse.Namespace) -> None:
    """å‘å¸ƒè‰ç¨¿"""
    token = get_access_token()
    
    resp = requests.post(
        ENDPOINTS["publish_submit"],
        params={"access_token": token},
        json={"media_id": args.media_id}
    )
    
    data = check_response(resp.json())
    
    if args.human:
        print("å‘å¸ƒä»»åŠ¡å·²æäº¤ï¼")
        print(f"publish_id: {data.get('publish_id')}")
    else:
        output_result(data)


def cmd_publish_status(args: argparse.Namespace) -> None:
    """æŸ¥è¯¢å‘å¸ƒçŠ¶æ€"""
    token = get_access_token()
    
    resp = requests.post(
        ENDPOINTS["publish_get"],
        params={"access_token": token},
        json={"publish_id": args.publish_id}
    )
    
    data = check_response(resp.json())
    
    if args.human:
        status_map = {0: "å‘å¸ƒæˆåŠŸ", 1: "å‘å¸ƒä¸­", 2: "å‘å¸ƒå¤±è´¥", 3: "å·²åˆ é™¤"}
        status = data.get("publish_status", -1)
        print(f"å‘å¸ƒçŠ¶æ€: {status_map.get(status, 'æœªçŸ¥')}")
        if data.get("article_id"):
            print(f"article_id: {data.get('article_id')}")
        if data.get("article_detail"):
            print(f"æ–‡ç« è¯¦æƒ…: {json.dumps(data['article_detail'], ensure_ascii=False)}")
    else:
        output_result(data)


def markdown_to_wechat_html(md_text: str) -> tuple[str, str]:
    """
    å°† Markdown è½¬æ¢ä¸ºå¾®ä¿¡å…¬ä¼—å·é£æ ¼çš„ HTMLï¼ˆå…¨å†…è” CSSï¼‰
    è¿”å› (title, html_content)
    """
    import re

    # é¢œè‰²/é£æ ¼é…ç½®
    ACCENT = "#4F6EF7"       # è“ç´«è‰²å¼ºè°ƒè‰²
    TEXT_MAIN = "#1a1a1a"    # æ­£æ–‡ä¸»è‰²
    TEXT_BODY = "#444444"    # æ­£æ–‡å†…å®¹è‰²
    TEXT_MUTED = "#888888"   # æ¬¡è¦æ–‡å­—
    BG_QUOTE = "#f7f8fc"     # å¼•ç”¨èƒŒæ™¯
    BORDER_LIGHT = "#e8e8e8" # è½»è¾¹æ¡†

    lines = md_text.strip().split('\n')

    # æå–æ ‡é¢˜ï¼ˆç¬¬ä¸€ä¸ª # è¡Œï¼‰
    title = ""
    body_lines = []
    for line in lines:
        if not title and line.startswith('# '):
            title = line[2:].strip()
        else:
            body_lines.append(line)

    def inline_styles(text: str) -> str:
        """å¤„ç†è¡Œå†… Markdown æ ·å¼"""
        # ç²—ä½“
        text = re.sub(r'\*\*(.+?)\*\*', f'<strong style="color:{TEXT_MAIN};font-weight:bold;">\\1</strong>', text)
        # æ–œä½“
        text = re.sub(r'\*(.+?)\*', r'<em>\1</em>', text)
        # è¡Œå†…ä»£ç 
        text = re.sub(r'`(.+?)`', f'<code style="background:#f0f0f0;padding:2px 6px;border-radius:3px;font-family:monospace;font-size:14px;color:#c7254e;">\\1</code>', text)
        return text

    parts = []
    i = 0

    while i < len(body_lines):
        line = body_lines[i]

        # H2
        if line.startswith('## '):
            text = inline_styles(line[3:].strip())
            parts.append(
                f'<h2 style="font-size:20px;font-weight:bold;color:{TEXT_MAIN};'
                f'margin:36px 0 16px;padding-bottom:8px;'
                f'border-bottom:2px solid {ACCENT};">{text}</h2>'
            )

        # H3
        elif line.startswith('### '):
            text = inline_styles(line[4:].strip())
            parts.append(
                f'<h3 style="font-size:17px;font-weight:bold;color:{TEXT_MAIN};'
                f'margin:28px 0 12px;padding-left:12px;'
                f'border-left:4px solid {ACCENT};">{text}</h3>'
            )

        # åˆ†å‰²çº¿
        elif line.strip() in ('---', '***', '___'):
            parts.append(
                f'<hr style="border:none;border-top:1px solid {BORDER_LIGHT};margin:32px 0;"/>'
            )

        # å¼•ç”¨å—
        elif line.startswith('> '):
            quote_lines = []
            while i < len(body_lines) and body_lines[i].startswith('> '):
                quote_lines.append(inline_styles(body_lines[i][2:].strip()))
                i += 1
            content = '<br/>'.join(quote_lines)
            parts.append(
                f'<blockquote style="background:{BG_QUOTE};border-left:4px solid {ACCENT};'
                f'margin:20px 0;padding:14px 18px;border-radius:0 6px 6px 0;'
                f'color:{TEXT_BODY};font-size:15px;line-height:1.8;">{content}</blockquote>'
            )
            continue

        # æ— åºåˆ—è¡¨ï¼ˆæ”¯æŒç»­è¡Œï¼šç¼©è¿›2+ç©ºæ ¼çš„è¡Œå±äºä¸Šä¸€ä¸ª itemï¼‰
        elif line.startswith('- ') or line.startswith('* '):
            items = []
            while i < len(body_lines):
                cur = body_lines[i]
                if cur.startswith('- ') or cur.startswith('* '):
                    # æ–° item å¼€å§‹
                    item_parts = [cur[2:].strip()]
                    i += 1
                    # åƒæ‰ç»­è¡Œï¼ˆç¼©è¿›2+ç©ºæ ¼ï¼Œä¸”ä¸æ˜¯æ–° bullet / æœ‰åºåˆ—è¡¨ / ç©ºè¡Œåçš„éç¼©è¿›è¡Œï¼‰
                    while i < len(body_lines):
                        nxt = body_lines[i]
                        if nxt.startswith('  ') and not nxt.startswith('- ') and not nxt.startswith('* ') and not re.match(r'^\d+\.\s', nxt):
                            item_parts.append(nxt.strip())
                            i += 1
                        else:
                            break
                    item_text = inline_styles(' '.join(item_parts))
                    items.append(
                        f'<li style="margin-bottom:10px;line-height:1.8;color:{TEXT_BODY};">{item_text}</li>'
                    )
                else:
                    break
            parts.append(
                f'<ul style="padding-left:24px;margin:16px 0 20px;">{"".join(items)}</ul>'
            )
            continue

        # æœ‰åºåˆ—è¡¨ï¼ˆæ”¯æŒç»­è¡Œï¼‰
        elif re.match(r'^\d+\.\s', line):
            items = []
            while i < len(body_lines):
                cur = body_lines[i]
                if re.match(r'^\d+\.\s', cur):
                    item_parts = [re.sub(r'^\d+\.\s', '', cur).strip()]
                    i += 1
                    while i < len(body_lines):
                        nxt = body_lines[i]
                        if nxt.startswith('  ') and not nxt.startswith('- ') and not nxt.startswith('* ') and not re.match(r'^\d+\.\s', nxt):
                            item_parts.append(nxt.strip())
                            i += 1
                        else:
                            break
                    item_text = inline_styles(' '.join(item_parts))
                    items.append(
                        f'<li style="margin-bottom:10px;line-height:1.8;color:{TEXT_BODY};">{item_text}</li>'
                    )
                else:
                    break
            parts.append(
                f'<ol style="padding-left:24px;margin:16px 0 20px;">{"".join(items)}</ol>'
            )
            continue

        # ä»£ç å—
        elif line.startswith('```'):
            code_lines = []
            i += 1
            while i < len(body_lines) and not body_lines[i].startswith('```'):
                code_lines.append(body_lines[i])
                i += 1
            code = '\n'.join(code_lines)
            parts.append(
                f'<pre style="background:#1e1e1e;color:#d4d4d4;padding:16px 20px;'
                f'border-radius:8px;overflow-x:auto;font-family:monospace;font-size:13px;'
                f'line-height:1.6;margin:20px 0;">{code}</pre>'
            )

        # ç©ºè¡Œ
        elif line.strip() == '':
            pass

        # æ™®é€šæ®µè½
        else:
            text = inline_styles(line.strip())
            parts.append(
                f'<p style="font-size:16px;line-height:1.9;color:{TEXT_BODY};'
                f'margin:14px 0;text-align:justify;">{text}</p>'
            )

        i += 1

    wrapper_open = (
        '<section style="max-width:677px;margin:0 auto;padding:0 16px;'
        'font-family:-apple-system,BlinkMacSystemFont,\'PingFang SC\','
        '\'Microsoft YaHei\',\'Helvetica Neue\',sans-serif;">'
    )
    html_content = wrapper_open + '\n' + '\n'.join(parts) + '\n</section>'

    return title, html_content


# ============ å°é¢å›¾ç”Ÿæˆå‘½ä»¤ ============

def cmd_gen_cover(args: argparse.Namespace) -> None:
    """ç”¨ Gemini Nano Banana Pro ç”Ÿæˆå…¬ä¼—å·å°é¢å›¾ (900Ã—383px, 2.35:1)"""
    try:
        from google import genai
        from google.genai import types
    except ImportError:
        print("é”™è¯¯: éœ€è¦å®‰è£… google-genai SDK: pip install google-genai", file=sys.stderr)
        sys.exit(1)

    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        print("é”™è¯¯: è¯·è®¾ç½®ç¯å¢ƒå˜é‡ GEMINI_API_KEY", file=sys.stderr)
        sys.exit(1)

    prompt = args.prompt
    output_path = Path(args.output) if args.output else Path("cover.png")

    # å°é¢å›¾å°ºå¯¸ï¼š900Ã—383 (2.35:1, å¾®ä¿¡å…¬ä¼—å·æ¨èæ¯”ä¾‹)
    # Gemini image gen outputs 1:1 by default, so we request wide format in prompt
    full_prompt = (
        f"Create a wide banner image (aspect ratio 2.35:1, like a cinema widescreen) for a WeChat article cover. "
        f"The image should be visually striking, modern, and suitable as a blog header. "
        f"Style: clean, professional, with subtle gradients or abstract elements. "
        f"Do NOT include any text or watermarks in the image. "
        f"Topic/mood: {prompt}"
    )

    client = genai.Client(api_key=api_key)

    # Try models: quality first (nano-banana-pro for best covers)
    models = [
        "nano-banana-pro-preview",
        "gemini-3-pro-image-preview",
        "gemini-2.5-flash-image",
    ]

    image_data = None
    used_model = None

    for model in models:
        try:
            response = client.models.generate_content(
                model=model,
                contents=full_prompt,
                config=types.GenerateContentConfig(
                    response_modalities=["IMAGE", "TEXT"],
                ),
            )
            # Extract image from response parts
            if response.candidates:
                for part in response.candidates[0].content.parts:
                    if hasattr(part, 'inline_data') and part.inline_data and part.inline_data.mime_type.startswith('image/'):
                        image_data = part.inline_data.data
                        used_model = model
                        break
            if image_data:
                break
        except Exception as e:
            print(f"âš ï¸ {model} å¤±è´¥: {e}", file=sys.stderr)
            continue

    if not image_data:
        print("é”™è¯¯: æ‰€æœ‰æ¨¡å‹éƒ½æ— æ³•ç”Ÿæˆå›¾ç‰‡", file=sys.stderr)
        sys.exit(1)

    # Save raw image first
    raw_path = output_path.with_suffix('.raw.png')
    with open(raw_path, 'wb') as f:
        f.write(image_data)

    # Resize/crop to exact 900Ã—383 using ffmpeg (always available on macOS)
    import subprocess
    try:
        subprocess.run([
            'ffmpeg', '-y', '-i', str(raw_path),
            '-vf', 'scale=900:383:force_original_aspect_ratio=increase,crop=900:383',
            str(output_path)
        ], capture_output=True, check=True)
        # Clean up raw file
        raw_path.unlink(missing_ok=True)
    except (subprocess.CalledProcessError, FileNotFoundError):
        # ffmpeg not available or failed, just rename raw
        import shutil
        shutil.move(str(raw_path), str(output_path))
        print("âš ï¸ ffmpeg ä¸å¯ç”¨ï¼Œå°é¢å›¾æœªè£å‰ªåˆ° 900Ã—383ï¼Œè¯·æ‰‹åŠ¨è°ƒæ•´", file=sys.stderr)

    result = {
        "output": str(output_path),
        "model": used_model,
        "size": "900x383",
        "prompt": prompt,
    }

    if args.human:
        print(f"âœ… å°é¢å›¾å·²ç”Ÿæˆ: {output_path}")
        print(f"ğŸ“ å°ºå¯¸: 900Ã—383px")
        print(f"ğŸ¤– æ¨¡å‹: {used_model}")
    else:
        output_result(result)


def cmd_md2html(args: argparse.Namespace) -> None:
    """å°† Markdown æ–‡ä»¶è½¬æ¢ä¸ºå¾®ä¿¡æ’ç‰ˆ HTML"""
    md_path = Path(args.md_file)
    if not md_path.exists():
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {md_path}", file=sys.stderr)
        sys.exit(1)

    with open(md_path, 'r', encoding='utf-8') as f:
        md_text = f.read()

    title, html = markdown_to_wechat_html(md_text)

    if args.output:
        out_path = Path(args.output)
        with open(out_path, 'w', encoding='utf-8') as f:
            f.write(html)
        print(f"âœ… å·²ä¿å­˜: {out_path}")
        print(f"ğŸ“ æ ‡é¢˜: {title}")
        print(f"ğŸ“ HTML é•¿åº¦: {len(html)} chars")
    else:
        print(html)


def cmd_article_list(args: argparse.Namespace) -> None:
    """è·å–å·²å‘å¸ƒæ–‡ç« åˆ—è¡¨"""
    token = get_access_token()
    
    payload = {
        "offset": args.offset,
        "count": args.count,
        "no_content": 1 if args.no_content else 0
    }
    
    resp = requests.post(
        ENDPOINTS["publish_batchget"],
        params={"access_token": token},
        json=payload
    )
    
    data = check_response(resp.json())
    
    if args.human:
        print(f"å…± {data.get('total_count', 0)} ç¯‡å·²å‘å¸ƒæ–‡ç« ")
        print("-" * 50)
        for i, item in enumerate(data.get("item", [])):
            content = item.get("content", {})
            news = content.get("news_item", [{}])[0] if content.get("news_item") else {}
            print(f"[{i + 1}] {news.get('title', 'æ— æ ‡é¢˜')}")
            print(f"    article_id: {item.get('article_id')}")
            print(f"    æ›´æ–°æ—¶é—´: {item.get('update_time')}")
            if news.get("url"):
                print(f"    é“¾æ¥: {news.get('url')}")
            print()
    else:
        output_result(data)


def main():
    parser = argparse.ArgumentParser(
        description="å¾®ä¿¡å…¬ä¼—å· API å‘½ä»¤è¡Œå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument("--human", "-H", action="store_true", help="äººç±»å¯è¯»æ ¼å¼è¾“å‡º")
    
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
    
    # token å‘½ä»¤
    parser_token = subparsers.add_parser("token", help="è·å– access_token")
    parser_token.set_defaults(func=cmd_token)
    
    # upload-cover å‘½ä»¤
    parser_upload_cover = subparsers.add_parser("upload-cover", help="ä¸Šä¼ æ°¸ä¹…ç´ æï¼ˆå°é¢å›¾ï¼‰")
    parser_upload_cover.add_argument("image_path", help="å›¾ç‰‡æ–‡ä»¶è·¯å¾„")
    parser_upload_cover.set_defaults(func=cmd_upload_cover)
    
    # upload-image å‘½ä»¤
    parser_upload_image = subparsers.add_parser("upload-image", help="ä¸Šä¼ å›¾æ–‡æ¶ˆæ¯å›¾ç‰‡")
    parser_upload_image.add_argument("image_path", help="å›¾ç‰‡æ–‡ä»¶è·¯å¾„")
    parser_upload_image.set_defaults(func=cmd_upload_image)
    
    # draft-add å‘½ä»¤
    parser_draft_add = subparsers.add_parser("draft-add", help="åˆ›å»ºè‰ç¨¿")
    parser_draft_add.add_argument("json_file", nargs="?", help="åŒ…å«è‰ç¨¿å†…å®¹çš„ JSON æ–‡ä»¶")
    parser_draft_add.add_argument("--title", help="æ–‡ç« æ ‡é¢˜")
    parser_draft_add.add_argument("--content", help="æ–‡ç« å†…å®¹ (HTML)")
    parser_draft_add.add_argument("--from-md", help="ä» Markdown æ–‡ä»¶è‡ªåŠ¨è½¬æ¢å†…å®¹ï¼ˆè‡ªåŠ¨æå–æ ‡é¢˜ï¼‰")
    parser_draft_add.add_argument("--thumb-media-id", help="å°é¢å›¾ media_id")
    parser_draft_add.add_argument("--author", help="ä½œè€…")
    parser_draft_add.add_argument("--digest", help="æ‘˜è¦")
    parser_draft_add.add_argument("--content-source-url", help="åŸæ–‡é“¾æ¥")
    parser_draft_add.add_argument("--need-open-comment", type=int, choices=[0, 1], help="æ˜¯å¦å¼€å¯è¯„è®º")
    parser_draft_add.add_argument("--only-fans-can-comment", type=int, choices=[0, 1], help="æ˜¯å¦ä»…ç²‰ä¸å¯è¯„è®º")
    parser_draft_add.set_defaults(func=cmd_draft_add)
    
    # draft-list å‘½ä»¤
    parser_draft_list = subparsers.add_parser("draft-list", help="åˆ—å‡ºæ‰€æœ‰è‰ç¨¿")
    parser_draft_list.add_argument("--offset", type=int, default=0, help="èµ·å§‹ä½ç½®")
    parser_draft_list.add_argument("--count", type=int, default=20, help="è·å–æ•°é‡ (æœ€å¤§20)")
    parser_draft_list.add_argument("--no-content", action="store_true", help="ä¸è¿”å›å†…å®¹")
    parser_draft_list.set_defaults(func=cmd_draft_list)
    
    # draft-get å‘½ä»¤
    parser_draft_get = subparsers.add_parser("draft-get", help="è·å–è‰ç¨¿è¯¦æƒ…")
    parser_draft_get.add_argument("media_id", help="è‰ç¨¿ media_id")
    parser_draft_get.set_defaults(func=cmd_draft_get)
    
    # draft-update å‘½ä»¤
    parser_draft_update = subparsers.add_parser("draft-update", help="æ›´æ–°è‰ç¨¿")
    parser_draft_update.add_argument("media_id", help="è‰ç¨¿ media_id")
    parser_draft_update.add_argument("--index", type=int, default=0, help="æ–‡ç« ç´¢å¼• (é»˜è®¤0)")
    parser_draft_update.add_argument("--title", help="æ–°æ ‡é¢˜")
    parser_draft_update.add_argument("--content", help="æ–°å†…å®¹ (HTML)")
    parser_draft_update.add_argument("--thumb-media-id", help="æ–°å°é¢å›¾ media_id")
    parser_draft_update.add_argument("--author", help="æ–°ä½œè€…")
    parser_draft_update.add_argument("--digest", help="æ–°æ‘˜è¦")
    parser_draft_update.set_defaults(func=cmd_draft_update)
    
    # draft-delete å‘½ä»¤
    parser_draft_delete = subparsers.add_parser("draft-delete", help="åˆ é™¤è‰ç¨¿")
    parser_draft_delete.add_argument("media_id", help="è‰ç¨¿ media_id")
    parser_draft_delete.set_defaults(func=cmd_draft_delete)
    
    # publish å‘½ä»¤
    parser_publish = subparsers.add_parser("publish", help="å‘å¸ƒè‰ç¨¿")
    parser_publish.add_argument("media_id", help="è‰ç¨¿ media_id")
    parser_publish.set_defaults(func=cmd_publish)
    
    # publish-status å‘½ä»¤
    parser_publish_status = subparsers.add_parser("publish-status", help="æŸ¥è¯¢å‘å¸ƒçŠ¶æ€")
    parser_publish_status.add_argument("publish_id", help="å‘å¸ƒä»»åŠ¡ ID")
    parser_publish_status.set_defaults(func=cmd_publish_status)
    
    # gen-cover å‘½ä»¤
    parser_gen_cover = subparsers.add_parser("gen-cover", help="ç”¨ Gemini ç”Ÿæˆå…¬ä¼—å·å°é¢å›¾ (900Ã—383px)")
    parser_gen_cover.add_argument("prompt", help="å°é¢å›¾ä¸»é¢˜/é£æ ¼æè¿°")
    parser_gen_cover.add_argument("-o", "--output", default="cover.png", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: cover.png)")
    parser_gen_cover.set_defaults(func=cmd_gen_cover)

    # md2html å‘½ä»¤
    parser_md2html = subparsers.add_parser("md2html", help="å°† Markdown è½¬æ¢ä¸ºå¾®ä¿¡æ’ç‰ˆ HTML")
    parser_md2html.add_argument("md_file", help="Markdown æ–‡ä»¶è·¯å¾„")
    parser_md2html.add_argument("-o", "--output", help="è¾“å‡º HTML æ–‡ä»¶è·¯å¾„ï¼ˆä¸æŒ‡å®šåˆ™æ‰“å°åˆ° stdoutï¼‰")
    parser_md2html.set_defaults(func=cmd_md2html)

    # article-list å‘½ä»¤
    parser_article_list = subparsers.add_parser("article-list", help="è·å–å·²å‘å¸ƒæ–‡ç« åˆ—è¡¨")
    parser_article_list.add_argument("--offset", type=int, default=0, help="èµ·å§‹ä½ç½®")
    parser_article_list.add_argument("--count", type=int, default=20, help="è·å–æ•°é‡ (æœ€å¤§20)")
    parser_article_list.add_argument("--no-content", action="store_true", help="ä¸è¿”å›å†…å®¹")
    parser_article_list.set_defaults(func=cmd_article_list)
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        sys.exit(1)
    
    args.func(args)


if __name__ == "__main__":
    main()
